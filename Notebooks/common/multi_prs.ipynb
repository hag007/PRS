{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import constants \n",
    "import scipy \n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "os.chdir(\"/specific/elkon/hagailevi/PRS/codebase\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery1=\"cimba_eur_brca1_oncoarray-5pcs\" # \"bcac_onco_eur-5pcs\"\n",
    "discovery2=\"cimba_eur_brca2_oncoarray-5pcs\"\n",
    "target=\"cimba_eur_brca2_icogs\"\n",
    "imp=\"impX_gen\"\n",
    "method=\"pt3\"\n",
    "th1=\"0.001\"\n",
    "th2=\"0.0000001\"\n",
    "calc_type=\"mono\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery1=\"bcac_onco_eur-5pcs\" # \"cimba_eur_brca1_oncoarray-5pcs\" # \"bcac_onco_eur-5pcs\"\n",
    "discovery2=\"cimba_eur_brca2_oncoarray-5pcs\"\n",
    "target=\"cimba_eur_brca2_icogs\"\n",
    "imp=\"impX_gen\"\n",
    "method=\"pt3\"\n",
    "th1=\"0.0000001\" # \"0.001\"\n",
    "th2=\"0.0000001\"\n",
    "calc_type=\"mono\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCORE1</th>\n",
       "      <th>SCORE2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163545</th>\n",
       "      <td>2.879107</td>\n",
       "      <td>1.686478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163547</th>\n",
       "      <td>0.450950</td>\n",
       "      <td>1.686478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163548</th>\n",
       "      <td>-0.871404</td>\n",
       "      <td>-0.444210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163590</th>\n",
       "      <td>0.339417</td>\n",
       "      <td>1.733390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163596</th>\n",
       "      <td>-2.288219</td>\n",
       "      <td>-1.556461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205032</th>\n",
       "      <td>0.173963</td>\n",
       "      <td>1.733390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205034</th>\n",
       "      <td>-0.291742</td>\n",
       "      <td>0.621129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205037</th>\n",
       "      <td>0.207291</td>\n",
       "      <td>-0.491114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205038</th>\n",
       "      <td>-0.289800</td>\n",
       "      <td>0.574238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205039</th>\n",
       "      <td>0.978012</td>\n",
       "      <td>0.574238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>641 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SCORE1    SCORE2  label\n",
       "FID                              \n",
       "163545  2.879107  1.686478      1\n",
       "163547  0.450950  1.686478      1\n",
       "163548 -0.871404 -0.444210      0\n",
       "163590  0.339417  1.733390      0\n",
       "163596 -2.288219 -1.556461      1\n",
       "...          ...       ...    ...\n",
       "205032  0.173963  1.733390      1\n",
       "205034 -0.291742  0.621129      0\n",
       "205037  0.207291 -0.491114      1\n",
       "205038 -0.289800  0.574238      0\n",
       "205039  0.978012  0.574238      1\n",
       "\n",
       "[641 rows x 3 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv(f\"{constants.PRSS_PATH}/{discovery1}_{target}/{imp}/prs.{calc_type}.{method}.{th1}.profile\", \\\n",
    "                  delim_whitespace=True, index_col=0)\n",
    "df1['SCORE']=scipy.stats.zscore(df1['SCORE'])\n",
    "df1=df1['SCORE'].rename(\"SCORE1\")\n",
    "\n",
    "\n",
    "df2=pd.read_csv(f\"{constants.PRSS_PATH}/{discovery2}_{target}/{imp}/prs.{calc_type}.{method}.{th2}.profile\", \\\n",
    "                 delim_whitespace=True, index_col=0)\n",
    "\n",
    "df2['SCORE']=scipy.stats.zscore(df2['SCORE'])\n",
    "df2=df2['SCORE'].rename(\"SCORE2\")\n",
    "\n",
    "df3=pd.read_csv(f\"{constants.DATASETS_PATH}/{target}/pheno\", \\\n",
    "                 delim_whitespace=True, index_col=0)['label']-1\n",
    "\n",
    "\n",
    "df_agg=pd.concat((df1,df2,df3), axis=1)\n",
    "\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_set(reg, X, y_true, p_high=99, p_low=1):\n",
    "\n",
    "    y_proba=reg.predict_proba(X)[:,1]\n",
    "    \n",
    "    th_high=np.percentile(y_proba, p_high)\n",
    "    th_low=np.percentile(y_proba, p_low)\n",
    "#     print(y_proba)\n",
    "#     print(th_high, max(y_proba))\n",
    "#     print(th_low, min(y_proba))\n",
    "#     print(len(X),len(y_true), len(y_true[y_proba<=th_low]))\n",
    "    print(f\"PRAUC: {average_precision_score(y_true, y_proba)} ({np.mean(y_true)})\")\n",
    "    print(f\"Top {100-p_high}% accuracy: {np.round(sum(y_true[y_proba>=th_high])/len(y_true[y_proba>=th_high]),4)}\")\n",
    "    print(f\"Bottom {p_low}% accuracy: {np.round((len(y_true[y_proba<=th_low])-sum(y_true[y_proba<=th_low]))/len(y_true[y_proba<=th_low]),4)}\")\n",
    "\n",
    "def calc_performance(X_train, X_test, y_train, y_test, reg):\n",
    "   \n",
    "    y_score_train=reg.predict(X_train)\n",
    "    y_score_test=reg.predict(X_test)\n",
    "    print(\"train:\")\n",
    "    calc_set(reg, X_train, y_train)\n",
    "    print(\"test:\")\n",
    "    calc_set(reg, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only score1:\n",
      "train:\n",
      "PRAUC: 0.6091438616907457 (0.5734265734265734)\n",
      "Top 1% accuracy: 0.4\n",
      "Bottom 1% accuracy: 0.6\n",
      "test:\n",
      "PRAUC: 0.6668271198551181 (0.660377358490566)\n",
      "Top 1% accuracy: 0.6667\n",
      "Bottom 1% accuracy: 0.0\n",
      "Only score2:\n",
      "train:\n",
      "PRAUC: 0.6141361030924186 (0.5734265734265734)\n",
      "Top 1% accuracy: 0.8889\n",
      "Bottom 1% accuracy: 0.5085\n",
      "test:\n",
      "PRAUC: 0.6850248298956624 (0.660377358490566)\n",
      "Top 1% accuracy: 0.7778\n",
      "Bottom 1% accuracy: 0.4194\n",
      "Both scores:\n",
      "train:\n",
      "PRAUC: 0.6222267468807554 (0.5734265734265734)\n",
      "Top 1% accuracy: 0.8\n",
      "Bottom 1% accuracy: 0.4\n",
      "test:\n",
      "PRAUC: 0.6889296316291218 (0.660377358490566)\n",
      "Top 1% accuracy: 1.0\n",
      "Bottom 1% accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "y=df_agg['label']\n",
    "X=df_agg[['SCORE1', 'SCORE2']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "print('Only score1:')\n",
    "score_names=['SCORE1']\n",
    "reg = LogisticRegression().fit(X_train[score_names], y_train)\n",
    "calc_performance(X_train[score_names], X_test[score_names], y_train, y_test, reg)\n",
    "\n",
    "print('Only score2:')\n",
    "score_names=['SCORE2']\n",
    "reg = LogisticRegression().fit(X_train[score_names], y_train)\n",
    "calc_performance(X_train[score_names], X_test[score_names], y_train, y_test, reg)\n",
    "\n",
    "print('Both scores:')\n",
    "score_names=['SCORE1', 'SCORE2']\n",
    "reg = LogisticRegression().fit(X_train, y_train)\n",
    "calc_performance(X_train[score_names], X_test[score_names], y_train, y_test, reg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
