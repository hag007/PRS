{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a889c8c",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">Note: this notebook requires Python3 kernel</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d60cb12",
   "metadata": {},
   "source": [
    "#### Init user specific variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9adc75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "user='maibendayan' # 'hagailevi'# 'maibendayan'\n",
    "os.chdir(f'/specific/elkon/{user}/PRS/codebase')\n",
    "user_prefix=\"mai_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea8f7a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from constants import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577cb741",
   "metadata": {},
   "source": [
    "#### Init analysis vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bae840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "discoveries=[f\"{user_prefix}bcac_onco_afr_no_1200_usa-5pcs\", f\"{user_prefix}bcac_onco_eur-5pcs\"] # [\"bcac_onco_eas1-5pcs\", \"bcac_onco_eur-5pcs\"] # [\"bcac_onco_afr_no_1200_usa-5pcs\", \"bcac_onco_eur-5pcs\"]\n",
    "### make sure to sort the discoveries lexicographically! ###\n",
    "mono_discovery0=discoveries[0]\n",
    "mono_discovery1=discoveries[1]\n",
    "multi_discovery=\"+\".join(discoveries)\n",
    "gwas_pops=[\"EAS\", \"EUR\"] \n",
    "target= f\"{user_prefix}bcac_onco_afr_1200_usa\" # \"bcac_onco_eas2\"\n",
    "imp=\"impX\"\n",
    "pheno=\"pheno\"\n",
    "\n",
    "# Method\n",
    "method=\"ls\"\n",
    "\n",
    "# Cross validation parameters\n",
    "n_folds=3\n",
    "n_reps=4\n",
    "base_rep=103 # 102 # n_repetitions+99\n",
    "\n",
    "# Multi PRS file suffices\n",
    "inner_test_name='validation.multi'\n",
    "test_name='test.multi'\n",
    "\n",
    "# Other file suffices\n",
    "metric='all.auroc' # 'or.all'\n",
    "rank_by='or'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ce917c",
   "metadata": {},
   "source": [
    "Concatenate all reps files into a single DF (and optinally saving the results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7a313ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outer_stat_file(discovery,target,imp,test_name,n_reps,n_folds, base_rep, method,save_file=False, rank_by=\"\"):\n",
    "    \n",
    "    metric_suffix=\"\"\n",
    "    if rank_by:\n",
    "        metric_suffix=f'_by_{rank_by}'\n",
    "\n",
    "    mono_outer_all_df=pd.DataFrame()\n",
    "    for cur_rep in range(1, n_reps+1):\n",
    "        prs_rep_path=f'{PRSS_PATH}{discovery}_{target}/{imp}/rep_{str(base_rep)}_{str(cur_rep)}/prs.cv.{method}___'\n",
    "        file_name=prs_rep_path+str(n_folds)+'_'+test_name+'.statistics'+metric_suffix+'.tsv'\n",
    "        df_stat=pd.read_csv(file_name, sep='\\t')\n",
    "        # df_stat.set_index('hp', inplace = True)\n",
    "        df_stat['rep']=cur_rep\n",
    "        df_stat[f'{metric}.outer.rank']=len(df_stat[metric])-df_stat[metric].rank()+1\n",
    "        \n",
    "        # sum the results\n",
    "        mono_outer_all_df=pd.concat([mono_outer_all_df,df_stat])\n",
    "\n",
    "    if save_file:\n",
    "        output_path=PRSS_PATH+discovery+'_'+target+'/'+imp+'/prs.cv.'+method+'___'\n",
    "        mono_outer_all_df.to_csv(output_path+'all_'+str(n_reps)+'_'+test_name+'.statistics'+param_suffix+'.tsv',mode=\"w\", sep='\\t')\n",
    "        print(mono_outer_all_df)\n",
    "        print (\"the next file was created: \"+output_path+'all_'+str(n_reps)+'_'+test_name+'.statistics'+param_suffix+'.tsv')\n",
    "\n",
    "    return mono_outer_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f5ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_name='test'\n",
    "# create_outer_stat_file(discoveries,target,imp,test_name,n_reps,n_folds,base_rep, method,save_file=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5c4627",
   "metadata": {},
   "source": [
    "Average of statistics results w/o using the multi step (mono-ethnic only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d5457f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not forget to run this first!\n",
    "test_name='test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "480bf727",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/specific/elkon/maibendayan/PRS/PRSs/mai_bcac_onco_afr_no_1200_usa-5pcs_mai_bcac_onco_afr_1200_usa/impX/rep_103_1/prs.cv.ls___3_test.statistics.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-68b3c80a71df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# non-EUR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_non_eur_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_outer_stat_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscoveries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_reps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_non_eur_all_agg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_non_eur_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{metric}.outer.rank'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rep'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4dee67fe6f19>\u001b[0m in \u001b[0;36mcreate_outer_stat_file\u001b[0;34m(discovery, target, imp, test_name, n_reps, n_folds, base_rep, method, save_file, rank_by)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprs_rep_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{PRSS_PATH}{discovery}_{target}/{imp}/rep_{str(base_rep)}_{str(cur_rep)}/prs.cv.{method}___'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprs_rep_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtest_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.statistics'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmetric_suffix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.tsv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdf_stat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# df_stat.set_index('hp', inplace = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdf_stat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rep'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_rep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gaga/hagailevi/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gaga/hagailevi/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gaga/hagailevi/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gaga/hagailevi/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gaga/hagailevi/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gaga/hagailevi/anaconda3/lib/python3.8/site-packages/pandas-1.5.1-py3.8-linux-x86_64.egg/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/gaga/hagailevi/anaconda3/lib/python3.8/site-packages/pandas-1.5.1-py3.8-linux-x86_64.egg/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/specific/elkon/maibendayan/PRS/PRSs/mai_bcac_onco_afr_no_1200_usa-5pcs_mai_bcac_onco_afr_1200_usa/impX/rep_103_1/prs.cv.ls___3_test.statistics.tsv'"
     ]
    }
   ],
   "source": [
    "# non-EUR\n",
    "df_non_eur_all=create_outer_stat_file(discoveries[0],target,imp,test_name,n_reps,n_folds,base_rep, method,save_file=False) \n",
    "df_non_eur_all_agg=df_non_eur_all[['hp', metric, f'{metric}.outer.rank', 'rep']].groupby('hp')[[metric]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73180921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EUR\n",
    "df_eur_all=create_outer_stat_file(discoveries[1],target,imp,test_name,n_reps,n_folds,base_rep, method,save_file=False)\n",
    "df_eur_all_agg=df_eur_all[['hp', metric, f'{metric}.outer.rank', 'rep']].groupby('hp')[[metric]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc85153b",
   "metadata": {},
   "source": [
    "Average of statistics results including the multi step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6f2b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not forget to run this first!\n",
    "multi_discovery='+'.join(discoveries)\n",
    "test_name='test.multi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi_all=create_outer_stat_file(multi_discovery,target,imp,test_name,n_reps,n_folds,base_rep, method,save_file=False, rank_by='or')\n",
    "df_multi_all_agg=df_multi_all[['hp', metric, f'{metric}.outer.rank', 'rep']].groupby('hp')[[metric]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94af4b07",
   "metadata": {},
   "source": [
    "#### Generic function for aggregating all folds by reps and hps\n",
    "the function returns the following dataframes:\n",
    "- The performance obtained on each rep according to the optimal **inner** hps - this is the \n",
    "- The performance obtained on each rep according to the optimal **outer** hps - along with extra metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf78e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prs_analysis(discovery,target,imp,outer_test_name,inner_test_name,n_folds,reps,base_rep,method,rank_by=\"\"):\n",
    "\n",
    "    df_outer_all = create_outer_stat_file(discovery,target,imp,outer_test_name,reps,n_folds,base_rep, method)\n",
    "    \n",
    "    metric_suffix=\"\"\n",
    "#     fold_range=list(range(1,n_folds+1))\n",
    "    if rank_by:\n",
    "        metric_suffix=f'_by_{rank_by}'\n",
    "#         fold_range=['avg']\n",
    "        \n",
    "    # df of statistics for inner loops over all reps:\n",
    "    df_cat=pd.DataFrame()\n",
    "    dfs=[]\n",
    "    for rep in range(1,reps+1):\n",
    "        for fold in range(1,n_folds+1):\n",
    "            path=PRSS_PATH+discovery+'_'+target+'/'+imp+'/rep_'+str(base_rep)+'_'+str(rep)+'/'+'prs.cv.'+method+'___'\n",
    "            path=f'{path}{fold}_{n_folds}_{inner_test_name}.statistics{metric_suffix}.tsv'\n",
    "            inner_df=pd.read_csv(path, sep='\\t')\n",
    "            inner_df['fold']=fold\n",
    "            inner_df['rep']=rep\n",
    "            dfs.append(inner_df)\n",
    "    \n",
    "    df_cat=pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "#     # Extract optimal hps for outer CV\n",
    "#     df_outer_optimal_hps=df_cat.loc[df_cat.groupby('rep')['or.all'].idxmax(),['rep', 'fold', 'hp']]\n",
    "#     display(df_outer_optimal_hps)\n",
    "    \n",
    "    # Check te performance of the optimal inner hps on the outer CV\n",
    "    df_inner_all=pd.concat(dfs, ignore_index=True)\n",
    "    df_inner_mean_or=df_inner_all.groupby(['rep', 'hp'])[[metric]].mean().reset_index()\n",
    "    df_optimal_hps=df_inner_mean_or.loc[df_inner_mean_or.groupby('rep')[metric].idxmax()]\n",
    "\n",
    "    # Check te performance of the optimal outer hps on the outer CV\n",
    "    df_outer_all.index=df_outer_all.apply(lambda a: f'{a[\"rep\"]}_{a[\"hp\"]}', axis=1)\n",
    "    print(df_outer_all.index)\n",
    "    result_true=df_outer_all.loc[df_optimal_hps.apply(lambda a: f'{a[\"rep\"]}_{a[\"hp\"]}', axis=1)]\n",
    "#     print('the or.all in the outer loop using the optimal hps in the inner loop: \\n(best practice)')\n",
    "#     display(result_true['or.all'])\n",
    "    \n",
    "#     print('the max or.all in the outer loop')\n",
    "#     display(df_outer_all.groupby('rep')[['or.all']].max())\n",
    "\n",
    "    \n",
    "    max_or_all = df_outer_all.groupby('rep')[metric].max()\n",
    "    result_max = pd.merge(df_outer_all, max_or_all, on=['rep', metric])\n",
    "# #     print('and their full info')\n",
    "# #     display(result_max)\n",
    "\n",
    "    return result_true, result_max\n",
    "\n",
    "# prs_analysis(mono_discovery0,target,imp,'test','validation',n_folds,reps,base_rep, method, rank_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2404ca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-EUR\n",
    "df_true, df_max=prs_analysis(mono_discovery0,target,imp,'test','validation',n_folds,n_reps,base_rep, method, rank_by)\n",
    "df_non_eur_outer_rep=df_true[['hp', metric, f'{metric}.outer.rank', 'rep']]\n",
    "display(df_non_eur_outer_rep)\n",
    "print(\"mean:\", round(df_true[metric].mean(),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e72355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EUR\n",
    "df_true, df_max=prs_analysis(mono_discovery1,target,imp,'test','validation',n_folds,n_reps,base_rep,method, rank_by)\n",
    "df_eur_outer_rep=df_true[['hp', metric, f'{metric}.outer.rank', 'rep']]\n",
    "display(df_eur_outer_rep)\n",
    "print(\"mean:\", round(df_true[metric].mean(),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTI\n",
    "rank_by=\"\"\n",
    "df_true, df_max=prs_analysis(multi_discovery,target,imp,'test.multi','validation.multi',n_folds,n_reps,base_rep,method)\n",
    "display(df_true[['hp', metric, f'{metric}.outer.rank', 'rep']]) # .groupby('hp')[['or.all']].mean()\n",
    "print(\"mean:\", round(df_true[metric].mean(),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b2f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTI2\n",
    "\n",
    "def extract_top_mono_hp_sets(a):\n",
    "    for i, (cur_non_eur, cur_eur) in enumerate(zip(df_non_eur_outer_rep['hp'], df_eur_outer_rep['hp'])):\n",
    "        if a['hp1']==cur_non_eur and a['hp2']==cur_eur and a['rep']==i+1:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "hp_series=df_multi_all['hp']\n",
    "hp_type=(float if method.startswith('pt') else str)\n",
    "df_multi_all['hp1']=hp_series.apply(lambda a : a.split('+')[0]).astype(hp_type).values\n",
    "df_multi_all['hp2']=hp_series.apply(lambda a : a.split('+')[1]).astype(hp_type).values\n",
    "df_multi_from_mono=df_multi_all[df_multi_all.apply(extract_top_mono_hp_sets, axis=1)]\n",
    "display(df_multi_from_mono[['hp', metric, f'{metric}.outer.rank', 'rep']])\n",
    "df_multi_from_mono[metric].mean()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
